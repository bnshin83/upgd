# December 1, 2025 - Mini-ImageNet Dataset Setup

## Problem
The original Mini-ImageNet dataset files only contained **1,000 samples** (toy subset), but the full dataset should have **60,000 samples** (600 per class × 100 classes) as described in the UPGD paper.

## Solution: Download Full Mini-ImageNet

### 1. Download Script Created: `download_mini_imagenet.py`

Downloads from Hugging Face (`timm/mini-imagenet`) and saves to scratch (not home folder).

**Key settings:**
- Cache location: `/scratch/gilbreth/shin283/.cache/huggingface/`
- Output: `dataset/mini-imagenet_data.pkl` and `dataset/mini-imagenet_targets.pkl`

### 2. Run Download (skip ResNet processing)

```bash
cd /scratch/gilbreth/shin283/upgd
conda activate /scratch/gilbreth/shin283/conda_envs/upgd
pip install datasets  # if not installed
python download_mini_imagenet.py --skip-resnet
```

This creates:
- `dataset/mini-imagenet_data.pkl` - 60,000 images (84×84×3, uint8), ~1.27 GB
- `dataset/mini-imagenet_targets.pkl` - 60,000 labels for 100 classes, ~480 KB

### 3. Process through ResNet-50 (requires GPU)

Create `preprocess_imagenet.py`:

```python
#!/usr/bin/env python3
"""Process Mini-ImageNet through ResNet-50 to get 2048-dim bottleneck features."""

import pickle
import torch
import torchvision
from PIL import Image
from tqdm import tqdm

def get_bottle_neck(model, x):
    x = model.conv1(x)
    x = model.bn1(x)
    x = model.relu(x)
    x = model.maxpool(x)
    x = model.layer1(x)
    x = model.layer2(x)
    x = model.layer3(x)
    x = model.layer4(x)
    x = model.avgpool(x)
    return torch.flatten(x, 1)

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # Load raw data
    print("Loading raw Mini-ImageNet data...")
    with open('dataset/mini-imagenet_data.pkl', 'rb') as f:
        data = pickle.load(f)
    print(f"Data shape: {data.shape}")
    
    # Load ResNet-50
    print("Loading pretrained ResNet-50...")
    resnet = torchvision.models.resnet50(pretrained=True)
    resnet = resnet.to(device)
    resnet.eval()
    for param in resnet.parameters():
        param.requires_grad_(False)
    
    # Transform
    transform = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])
    
    # Process in batches
    n_samples = len(data)
    batch_size = 200
    processed_data = torch.zeros((n_samples, 2048))
    
    print(f"Processing {n_samples} images through ResNet-50...")
    with torch.no_grad():
        for i in tqdm(range(0, n_samples, batch_size)):
            batch_end = min(i + batch_size, n_samples)
            batch_images = []
            for j in range(i, batch_end):
                img = Image.fromarray(data[j])
                img_tensor = transform(img)
                batch_images.append(img_tensor)
            batch_tensor = torch.stack(batch_images).to(device)
            features = get_bottle_neck(resnet, batch_tensor)
            processed_data[i:batch_end] = features.cpu()
    
    # Save
    print("Saving processed_imagenet.pkl...")
    with open('processed_imagenet.pkl', 'wb') as f:
        pickle.dump(processed_data, f)
    
    print(f"Done! Shape: {processed_data.shape}")

if __name__ == "__main__":
    main()
```

### 4. SLURM Job for ResNet Processing

Create `preprocess_job.sh`:

```bash
#!/bin/bash
#SBATCH --job-name=preprocess_imagenet
#SBATCH --account=jhaddock
#SBATCH --partition=a100-80gb
#SBATCH --output=/scratch/gilbreth/shin283/upgd/logs/%j_preprocess_imagenet.out
#SBATCH --error=/scratch/gilbreth/shin283/upgd/logs/%j_preprocess_imagenet.err
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --gpus-per-node=1
#SBATCH --mem=32G

cd /scratch/gilbreth/shin283/upgd
module load cuda
export PYTHONPATH=/scratch/gilbreth/shin283/upgd:$PYTHONPATH

eval "$(conda shell.bash hook)"
conda activate /scratch/gilbreth/shin283/conda_envs/upgd

echo "Starting ResNet-50 preprocessing..."
python preprocess_imagenet.py
echo "Done!"
```

Submit with:
```bash
sbatch preprocess_job.sh
```

### 5. Verify Final Dataset

```python
import pickle

# Check raw data
with open('dataset/mini-imagenet_data.pkl', 'rb') as f:
    data = pickle.load(f)
print(f"Raw data: {data.shape}")  # Should be (60000, 84, 84, 3)

# Check targets
with open('dataset/mini-imagenet_targets.pkl', 'rb') as f:
    targets = pickle.load(f)
print(f"Targets: {len(targets)} samples, {len(set(targets))} classes")  # 60000, 100

# Check processed features
with open('processed_imagenet.pkl', 'rb') as f:
    processed = pickle.load(f)
print(f"Processed: {processed.shape}")  # Should be (60000, 2048)
```

## Dataset Specifications (from UPGD paper)

> The mini-ImageNet (Vinyals et al. 2016) is a subset of the ImageNet dataset. The mini-ImageNet dataset contains **60,000 RGB images** of size **84 × 84** belonging to **100 classes**; each class has **600 images**. In Label-permuted mini-ImageNet, the labels are permuted every **2500 time steps**. Each learner uses a fully connected network of two layers on top of a **pre-trained ResNet-50** (He et al. 2016) on ImageNet with fixed weights.

## Hyperparameters for Mini-ImageNet

From experiments:
- Learning rate (α): 0.01
- Sigma (σ): 0.01
- Beta utility (βu): 0.9
- Weight decay (λ): 0.001

